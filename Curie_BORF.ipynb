{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e05f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skopt import Optimizer\n",
    "from skopt.learning import RandomForestRegressor\n",
    "from skopt.space import Integer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb86fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e00640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounds of the experimental conditions\n",
    "bounds = [\n",
    "         Integer(5, 75, name='metal_amount'), #range 0.5-7.5ml, step 0.1ml \n",
    "         Integer(5, 15, name='modulator'),   #amount of modulator NaOH (100mg/mL), range 0.5-1.5ml, step 0.1ml\n",
    "         Integer(0, 30, name='add_solvent'), #amount of additional DI water, range 0-3.0mL, step 0.1ml\n",
    "         Integer(1, 12, name='reaction_time'),   #reaction time, range 5-60 min, step 5 min\n",
    "         Integer(10, 30, name='reaction_temperature')#reaction temperature, range 50-150C, step 5 C\n",
    "         ] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24130e8d",
   "metadata": {},
   "source": [
    "Only run for the FIRST time------\n",
    "Initialize the Bayesian optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04caedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, criterion=\"squared_error\")\n",
    "\n",
    "# Initial dataset\n",
    "data = pd.read_csv(\"4N5N_dat.csv\")\n",
    "X_initial = data[['metal_amount', 'modulator', 'add_solvent', 'reaction_time', 'reaction_temperature']].values\n",
    "y_initial = -data[\"crystallinity\"].values\n",
    "\n",
    "optimizer = Optimizer(bounds, base_estimator=rf, acq_func=\"EI\", n_initial_points=data.shape[0], random_state=42)\n",
    "optimizer.tell(X_initial.tolist(), y_initial.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a696c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first batch of experimental conditions\n",
    "batch_size = 3 \n",
    "MAX_ATTEMPT = 3\n",
    "ntry = 0\n",
    "while ntry < MAX_ATTEMPT:\n",
    "    try:\n",
    "        next_params = optimizer.ask(n_points=batch_size) #, strategy=\"cl_max\")\n",
    "        next_params_dict = pd.DataFrame({dim.name: value for dim, value in zip(bounds, np.array(next_params).T)})\n",
    "        break\n",
    "    except UserWarning:\n",
    "        ntry += 1\n",
    "        if ntry == MAX_ATTEMPT:\n",
    "            print(\"Exceed max attempts...Drop duplicates if detected\")\n",
    "            next_params = optimizer.ask(n_points=batch_size)\n",
    "            next_params_dict = pd.DataFrame({dim.name: value for dim, value in zip(bounds, np.array(next_params).T)})\n",
    "            break\n",
    "        print(\"One or more suggested experiments are duplicates of previous trials...Try again\")\n",
    "\n",
    "new_data = pd.concat([data, next_params_dict]).drop_duplicates(data.columns[:5], keep=\"first\")\n",
    "\n",
    "if new_data.shape[0] == data.shape[0]:\n",
    "    print(\"No new experiments proposed...Manually change batch size\")\n",
    "else:   \n",
    "    print(f\"Suggested experiments: \\n {new_data.tail(new_data.shape[0] - data.shape[0])[data.columns[:5]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new experiment conditions to data file\n",
    "new_data.to_csv(\"4N5N_dat.csv\", index=False)\n",
    "\n",
    "# save current optimizer\n",
    "with open(\"saved_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(optimizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081eb55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01501bc6",
   "metadata": {},
   "source": [
    "For subsequent update and query of next experiment conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bf549d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved optimizer\n",
    "with open(\"saved_model.pkl\", \"rb\") as f:\n",
    "    optimizer = pickle.load(f)\n",
    "\n",
    "# load exp data\n",
    "data = pd.read_csv(\"4N5N_dat.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d545529b",
   "metadata": {},
   "source": [
    "Before running the following cell:  \n",
    "Perform the experiments with the suggested conditions and manually enter the crystallinity scores to the dat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization loop\n",
    "batch_size = 3 # this is the number of experiments performed\n",
    "ndata = data.shape[0]\n",
    "#data.loc[ndata-batch_size: ndata-1, \"FHWM\"] = [...]\n",
    "#data.loc[ndata-batch_size: ndata-1, \"height\"] = [...]\n",
    "#data[\"crystallinity\"] = data[\"height\"]/data[\"FHWM\"]\n",
    "next_params_dict = data.tail(batch_size)\n",
    "\n",
    "# Update the dataset and optimizer\n",
    "optimizer.tell(next_params_dict[['metal_amount', 'modulator', 'add_solvent', 'reaction_time', 'reaction_temperature']].values.tolist(), \n",
    "           (-next_params_dict[\"crystallinity\"].values).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad1a4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new experiment conditions to data file\n",
    "new_data.to_csv(\"4N5N_dat.csv\", index=False)\n",
    "\n",
    "# save current optimizer\n",
    "with open(\"saved_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(optimizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4746daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best experimental conditions\n",
    "best_params = optimizer.Xi[np.argmax(optimizer.yi)]\n",
    "best_params_dict = {dim.name: value for dim, value in zip(bounds, best_params)}\n",
    "print(f\"Best experimental conditions: {best_params_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc3fe088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BORF_Zach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
